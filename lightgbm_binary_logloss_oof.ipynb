{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc,roc_curve,log_loss\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gal = pd.read_pickle('../input/train_gal_20181214.pickle')\n",
    "train_ex_gal = pd.read_pickle('../input/train_ex_gal_20181214.pickle')\n",
    "test_gal = pd.read_pickle('../input/test_gal_20181214.pickle')\n",
    "test_ex_gal = pd.read_pickle('../input/test_ex_gal_20181214.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sixth_band = pd.read_pickle('../input/train_sixth_byband.pickle')\n",
    "test_sixth_band = pd.read_pickle('../input/test_sixth_byband.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fix_band_0_stats = pd.read_pickle('../input/train_band_0_fix_stats.pickle')\n",
    "test_fix_band_0_stats = pd.read_pickle('../input/test_band_0_fix_stats.pickle')\n",
    "train_fix_band_1_stats = pd.read_pickle('../input/train_band_1_fix_stats.pickle')\n",
    "test_fix_band_1_stats = pd.read_pickle('../input/test_band_1_fix_stats.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gal = pd.merge(train_gal,train_fix_band_0_stats,on='object_id',how='left')\n",
    "train_gal = pd.merge(train_gal,train_fix_band_1_stats,on='object_id',how='left')\n",
    "\n",
    "train_ex_gal = pd.merge(train_ex_gal,train_sixth_band,on='object_id',how='left')\n",
    "train_ex_gal = pd.merge(train_ex_gal,train_fix_band_0_stats,on='object_id',how='left')\n",
    "train_ex_gal = pd.merge(train_ex_gal,train_fix_band_1_stats,on='object_id',how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gal = pd.merge(test_gal,test_fix_band_0_stats,on='object_id',how='left')\n",
    "test_gal = pd.merge(test_gal,test_fix_band_1_stats,on='object_id',how='left')\n",
    "\n",
    "test_ex_gal = pd.merge(test_ex_gal,test_sixth_band,on='object_id',how='left')\n",
    "test_ex_gal = pd.merge(test_ex_gal,test_fix_band_0_stats ,on='object_id',how='left')\n",
    "test_ex_gal = pd.merge(test_ex_gal,test_fix_band_1_stats ,on='object_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>object_id</th>\n",
       "      <th>gal_b</th>\n",
       "      <th>hostgal_photoz</th>\n",
       "      <th>hostgal_photoz_err</th>\n",
       "      <th>target</th>\n",
       "      <th>haversine</th>\n",
       "      <th>latlon1</th>\n",
       "      <th>diff_hostgal</th>\n",
       "      <th>diff_hostgal_abs</th>\n",
       "      <th>passband_0_ratio_detect</th>\n",
       "      <th>passband_1_ratio_detect</th>\n",
       "      <th>passband_2_ratio_detect</th>\n",
       "      <th>passband_3_ratio_detect</th>\n",
       "      <th>passband_4_ratio_detect</th>\n",
       "      <th>passband_5_ratio_detect</th>\n",
       "      <th>passband_0_ratio</th>\n",
       "      <th>passband_1_ratio</th>\n",
       "      <th>passband_2_ratio</th>\n",
       "      <th>passband_3_ratio</th>\n",
       "      <th>passband_4_ratio</th>\n",
       "      <th>passband_5_ratio</th>\n",
       "      <th>ratio_by_band_median</th>\n",
       "      <th>ratio_by_band_var</th>\n",
       "      <th>flux_max_detected</th>\n",
       "      <th>flux_min_detected</th>\n",
       "      <th>flux_mean_detected</th>\n",
       "      <th>flux_median_detected</th>\n",
       "      <th>flux_skew_detected</th>\n",
       "      <th>flux_max_min_detected</th>\n",
       "      <th>flux_max</th>\n",
       "      <th>flux_min</th>\n",
       "      <th>flux_mean</th>\n",
       "      <th>flux_median</th>\n",
       "      <th>flux_skew</th>\n",
       "      <th>flux_max_min</th>\n",
       "      <th>detected_mean</th>\n",
       "      <th>mjd_diff</th>\n",
       "      <th>mjd_halfflux</th>\n",
       "      <th>mjd_sixthflux</th>\n",
       "      <th>diff_baba_mjd</th>\n",
       "      <th>max_flux_0_1</th>\n",
       "      <th>flux__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>flux__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>flux__longest_strike_above_mean</th>\n",
       "      <th>flux__number_crossing_m__m_1</th>\n",
       "      <th>symm</th>\n",
       "      <th>0__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>0__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>0__longest_strike_above_mean</th>\n",
       "      <th>0__number_crossing_m__m_1</th>\n",
       "      <th>0__ratio_beyond_r_sigma__r_0.5</th>\n",
       "      <th>0__sample_entropy</th>\n",
       "      <th>1__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>1__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>1__longest_strike_above_mean</th>\n",
       "      <th>1__number_crossing_m__m_1</th>\n",
       "      <th>1__ratio_beyond_r_sigma__r_0.5</th>\n",
       "      <th>1__sample_entropy</th>\n",
       "      <th>2__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>2__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>2__longest_strike_above_mean</th>\n",
       "      <th>2__number_crossing_m__m_1</th>\n",
       "      <th>2__ratio_beyond_r_sigma__r_0.5</th>\n",
       "      <th>2__sample_entropy</th>\n",
       "      <th>3__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>3__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>3__longest_strike_above_mean</th>\n",
       "      <th>3__number_crossing_m__m_1</th>\n",
       "      <th>3__ratio_beyond_r_sigma__r_0.5</th>\n",
       "      <th>3__sample_entropy</th>\n",
       "      <th>4__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>4__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>4__longest_strike_above_mean</th>\n",
       "      <th>4__number_crossing_m__m_1</th>\n",
       "      <th>4__ratio_beyond_r_sigma__r_0.5</th>\n",
       "      <th>4__sample_entropy</th>\n",
       "      <th>5__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>5__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>5__longest_strike_above_mean</th>\n",
       "      <th>5__number_crossing_m__m_1</th>\n",
       "      <th>5__ratio_beyond_r_sigma__r_0.5</th>\n",
       "      <th>5__sample_entropy</th>\n",
       "      <th>flux_ratio_sq_sum</th>\n",
       "      <th>flux_ratio_sq_skew</th>\n",
       "      <th>flux_by_flux_ratio_sq_sum</th>\n",
       "      <th>flux_by_flux_ratio_sq_skew</th>\n",
       "      <th>flux_dif</th>\n",
       "      <th>flux_dif2</th>\n",
       "      <th>flux_w_mean</th>\n",
       "      <th>flux_dif3</th>\n",
       "      <th>flux_max__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>flux_max__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>flux_max__kurtosis</th>\n",
       "      <th>flux_max__skewness</th>\n",
       "      <th>flux_min__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>flux_min__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>flux_min__kurtosis</th>\n",
       "      <th>flux_min__skewness</th>\n",
       "      <th>flux_mean__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>...</th>\n",
       "      <th>flux_err_rate_min</th>\n",
       "      <th>flux_err_rate_mean</th>\n",
       "      <th>flux_err_rate_median</th>\n",
       "      <th>flux_err_rate_var</th>\n",
       "      <th>flux_err_rate_skew</th>\n",
       "      <th>flux_err_rate_max_min</th>\n",
       "      <th>0__kurtosis</th>\n",
       "      <th>0__skewness</th>\n",
       "      <th>1__kurtosis</th>\n",
       "      <th>1__skewness</th>\n",
       "      <th>2__kurtosis</th>\n",
       "      <th>2__skewness</th>\n",
       "      <th>3__kurtosis</th>\n",
       "      <th>3__skewness</th>\n",
       "      <th>4__kurtosis</th>\n",
       "      <th>4__skewness</th>\n",
       "      <th>5__kurtosis</th>\n",
       "      <th>5__skewness</th>\n",
       "      <th>0__maximum</th>\n",
       "      <th>0__mean</th>\n",
       "      <th>0__median</th>\n",
       "      <th>0__minimum</th>\n",
       "      <th>0__standard_deviation</th>\n",
       "      <th>1__maximum</th>\n",
       "      <th>1__mean</th>\n",
       "      <th>1__median</th>\n",
       "      <th>1__minimum</th>\n",
       "      <th>1__standard_deviation</th>\n",
       "      <th>2__maximum</th>\n",
       "      <th>2__mean</th>\n",
       "      <th>2__median</th>\n",
       "      <th>2__minimum</th>\n",
       "      <th>2__standard_deviation</th>\n",
       "      <th>3__maximum</th>\n",
       "      <th>3__mean</th>\n",
       "      <th>3__median</th>\n",
       "      <th>3__minimum</th>\n",
       "      <th>3__standard_deviation</th>\n",
       "      <th>4__maximum</th>\n",
       "      <th>4__mean</th>\n",
       "      <th>4__median</th>\n",
       "      <th>4__minimum</th>\n",
       "      <th>4__standard_deviation</th>\n",
       "      <th>5__maximum</th>\n",
       "      <th>5__mean</th>\n",
       "      <th>5__median</th>\n",
       "      <th>5__minimum</th>\n",
       "      <th>5__standard_deviation</th>\n",
       "      <th>diff_flux__kurtosis_diff</th>\n",
       "      <th>diff_flux__maximum_diff</th>\n",
       "      <th>diff_flux__mean_diff</th>\n",
       "      <th>diff_flux__median_diff</th>\n",
       "      <th>diff_flux__minimum_diff</th>\n",
       "      <th>diff_flux__skewness_diff</th>\n",
       "      <th>diff_flux__standard_deviation_diff</th>\n",
       "      <th>diff_flux__maximum_diff_det</th>\n",
       "      <th>diff_flux__median_diff_det</th>\n",
       "      <th>diff_flux__minimum_diff_det</th>\n",
       "      <th>0__maximum_diff</th>\n",
       "      <th>0__median_diff</th>\n",
       "      <th>0__minimum_diff</th>\n",
       "      <th>1__maximum_diff</th>\n",
       "      <th>1__median_diff</th>\n",
       "      <th>1__minimum_diff</th>\n",
       "      <th>2__maximum_diff</th>\n",
       "      <th>2__median_diff</th>\n",
       "      <th>2__minimum_diff</th>\n",
       "      <th>3__maximum_diff</th>\n",
       "      <th>3__median_diff</th>\n",
       "      <th>3__minimum_diff</th>\n",
       "      <th>4__maximum_diff</th>\n",
       "      <th>4__median_diff</th>\n",
       "      <th>4__minimum_diff</th>\n",
       "      <th>5__maximum_diff</th>\n",
       "      <th>5__median_diff</th>\n",
       "      <th>5__minimum_diff</th>\n",
       "      <th>sixth_band_0</th>\n",
       "      <th>sixth_band_1</th>\n",
       "      <th>sixth_band_2</th>\n",
       "      <th>sixth_band_3</th>\n",
       "      <th>sixth_band_4</th>\n",
       "      <th>sixth_band_5</th>\n",
       "      <th>second_band_0</th>\n",
       "      <th>second_band_1</th>\n",
       "      <th>second_band_2</th>\n",
       "      <th>second_band_3</th>\n",
       "      <th>second_band_4</th>\n",
       "      <th>second_band_5</th>\n",
       "      <th>band_0_flux_max</th>\n",
       "      <th>band_0_flux_min</th>\n",
       "      <th>band_0_flux_mean</th>\n",
       "      <th>band_0_flux_med</th>\n",
       "      <th>band_0_flux_skew</th>\n",
       "      <th>band_0_flux_std</th>\n",
       "      <th>band_1_flux_max</th>\n",
       "      <th>band_1_flux_min</th>\n",
       "      <th>band_1_flux_mean</th>\n",
       "      <th>band_1_flux_med</th>\n",
       "      <th>band_1_flux_skew</th>\n",
       "      <th>band_1_flux_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>615</td>\n",
       "      <td>-51.753706</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>92</td>\n",
       "      <td>0.319006</td>\n",
       "      <td>-1.528827</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.168168</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>0.156156</td>\n",
       "      <td>0.178977</td>\n",
       "      <td>0.164773</td>\n",
       "      <td>0.164773</td>\n",
       "      <td>0.164773</td>\n",
       "      <td>0.164773</td>\n",
       "      <td>0.161932</td>\n",
       "      <td>0.164773</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>660.626343</td>\n",
       "      <td>-1100.440063</td>\n",
       "      <td>-130.266769</td>\n",
       "      <td>-102.768921</td>\n",
       "      <td>-0.291382</td>\n",
       "      <td>7.473675</td>\n",
       "      <td>0.946023</td>\n",
       "      <td>660.626343</td>\n",
       "      <td>-1100.440063</td>\n",
       "      <td>-123.097000</td>\n",
       "      <td>-89.477524</td>\n",
       "      <td>-0.349540</td>\n",
       "      <td>7.473675</td>\n",
       "      <td>873.792969</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>13.996094</td>\n",
       "      <td>13.980469</td>\n",
       "      <td>-535.443542</td>\n",
       "      <td>43330.143254</td>\n",
       "      <td>15303.668045</td>\n",
       "      <td>19.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.985612</td>\n",
       "      <td>205.036927</td>\n",
       "      <td>1628.427737</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>2.016440</td>\n",
       "      <td>22370.594833</td>\n",
       "      <td>2806.374162</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>1.933884</td>\n",
       "      <td>7780.500810</td>\n",
       "      <td>2805.598110</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>1.959309</td>\n",
       "      <td>7024.003069</td>\n",
       "      <td>2536.068845</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>1.861271</td>\n",
       "      <td>3245.366350</td>\n",
       "      <td>2741.539788</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.775862</td>\n",
       "      <td>1.921409</td>\n",
       "      <td>2704.641263</td>\n",
       "      <td>2893.344216</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>1.886318</td>\n",
       "      <td>-9.601766e+08</td>\n",
       "      <td>-1.414322</td>\n",
       "      <td>2.929669e+06</td>\n",
       "      <td>0.812722</td>\n",
       "      <td>7.473675</td>\n",
       "      <td>-14.306331</td>\n",
       "      <td>-327.742340</td>\n",
       "      <td>-5.373326</td>\n",
       "      <td>7.864678</td>\n",
       "      <td>6.281597</td>\n",
       "      <td>0.314536</td>\n",
       "      <td>-0.527777</td>\n",
       "      <td>8.094029</td>\n",
       "      <td>6.729821</td>\n",
       "      <td>1.487434</td>\n",
       "      <td>-0.763272</td>\n",
       "      <td>6.616880</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.925288</td>\n",
       "      <td>-4.159871</td>\n",
       "      <td>1.146181</td>\n",
       "      <td>1.219583</td>\n",
       "      <td>2.371641</td>\n",
       "      <td>1.203312</td>\n",
       "      <td>-1.475181</td>\n",
       "      <td>0.128917</td>\n",
       "      <td>-1.255123</td>\n",
       "      <td>0.415581</td>\n",
       "      <td>-1.409885</td>\n",
       "      <td>0.339918</td>\n",
       "      <td>-1.449858</td>\n",
       "      <td>0.293128</td>\n",
       "      <td>-1.548319</td>\n",
       "      <td>0.200096</td>\n",
       "      <td>-1.592820</td>\n",
       "      <td>0.125269</td>\n",
       "      <td>125.182808</td>\n",
       "      <td>-3.254554</td>\n",
       "      <td>-10.015225</td>\n",
       "      <td>-116.913223</td>\n",
       "      <td>83.275841</td>\n",
       "      <td>660.626343</td>\n",
       "      <td>-385.699921</td>\n",
       "      <td>-488.057983</td>\n",
       "      <td>-1100.440063</td>\n",
       "      <td>596.576904</td>\n",
       "      <td>611.984558</td>\n",
       "      <td>-134.146576</td>\n",
       "      <td>-265.686005</td>\n",
       "      <td>-681.858887</td>\n",
       "      <td>451.180817</td>\n",
       "      <td>445.737061</td>\n",
       "      <td>-121.103500</td>\n",
       "      <td>-162.170944</td>\n",
       "      <td>-530.644592</td>\n",
       "      <td>332.520874</td>\n",
       "      <td>381.953735</td>\n",
       "      <td>-55.954590</td>\n",
       "      <td>-103.541367</td>\n",
       "      <td>-422.184509</td>\n",
       "      <td>289.276978</td>\n",
       "      <td>378.188141</td>\n",
       "      <td>-47.449844</td>\n",
       "      <td>-85.524307</td>\n",
       "      <td>-422.815094</td>\n",
       "      <td>292.182281</td>\n",
       "      <td>1.561865</td>\n",
       "      <td>1007.002441</td>\n",
       "      <td>202.114075</td>\n",
       "      <td>107.974808</td>\n",
       "      <td>0.076019</td>\n",
       "      <td>1.432323</td>\n",
       "      <td>210.771271</td>\n",
       "      <td>1007.002441</td>\n",
       "      <td>126.217438</td>\n",
       "      <td>0.076019</td>\n",
       "      <td>191.556000</td>\n",
       "      <td>39.526798</td>\n",
       "      <td>0.170685</td>\n",
       "      <td>1745.011963</td>\n",
       "      <td>573.419739</td>\n",
       "      <td>4.854187</td>\n",
       "      <td>1280.468140</td>\n",
       "      <td>412.171204</td>\n",
       "      <td>6.889648</td>\n",
       "      <td>879.547913</td>\n",
       "      <td>347.493164</td>\n",
       "      <td>1.488678</td>\n",
       "      <td>767.241089</td>\n",
       "      <td>252.360184</td>\n",
       "      <td>4.495239</td>\n",
       "      <td>734.515442</td>\n",
       "      <td>214.830948</td>\n",
       "      <td>5.912170</td>\n",
       "      <td>3.011719</td>\n",
       "      <td>241.230469</td>\n",
       "      <td>241.230469</td>\n",
       "      <td>16.023438</td>\n",
       "      <td>3.003906</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.003906</td>\n",
       "      <td>241.230469</td>\n",
       "      <td>241.230469</td>\n",
       "      <td>13.054688</td>\n",
       "      <td>3.003906</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.251828e+02</td>\n",
       "      <td>-1.169132e+02</td>\n",
       "      <td>-3.254554e+00</td>\n",
       "      <td>-1.001523e+01</td>\n",
       "      <td>0.128917</td>\n",
       "      <td>8.394473e+01</td>\n",
       "      <td>6.606263e+02</td>\n",
       "      <td>-1.100440e+03</td>\n",
       "      <td>-2.599232e+02</td>\n",
       "      <td>-349.215576</td>\n",
       "      <td>0.185580</td>\n",
       "      <td>5.460072e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>713</td>\n",
       "      <td>-54.460748</td>\n",
       "      <td>1.6267</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>88</td>\n",
       "      <td>1.698939</td>\n",
       "      <td>3.258921</td>\n",
       "      <td>0.1914</td>\n",
       "      <td>0.1914</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>11.330316</td>\n",
       "      <td>-12.394593</td>\n",
       "      <td>-6.061436</td>\n",
       "      <td>-8.975166</td>\n",
       "      <td>1.308961</td>\n",
       "      <td>3.166525</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>14.770886</td>\n",
       "      <td>-14.735178</td>\n",
       "      <td>-1.423351</td>\n",
       "      <td>-0.873032</td>\n",
       "      <td>0.014989</td>\n",
       "      <td>3.384596</td>\n",
       "      <td>846.800781</td>\n",
       "      <td>3.042969</td>\n",
       "      <td>3.042969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.380808</td>\n",
       "      <td>498.172763</td>\n",
       "      <td>1258.252791</td>\n",
       "      <td>50.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.986149</td>\n",
       "      <td>190.427854</td>\n",
       "      <td>299.586560</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>2.179983</td>\n",
       "      <td>57.109049</td>\n",
       "      <td>192.539230</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>2.335591</td>\n",
       "      <td>44.477326</td>\n",
       "      <td>191.057527</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>2.124602</td>\n",
       "      <td>55.270115</td>\n",
       "      <td>212.522263</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>2.146581</td>\n",
       "      <td>50.414646</td>\n",
       "      <td>203.892482</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>2.221544</td>\n",
       "      <td>100.473774</td>\n",
       "      <td>143.963093</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>-2.875087e+04</td>\n",
       "      <td>-3.454554</td>\n",
       "      <td>5.886068e+03</td>\n",
       "      <td>3.439423</td>\n",
       "      <td>3.384596</td>\n",
       "      <td>-20.730003</td>\n",
       "      <td>-4.884563</td>\n",
       "      <td>-6.040676</td>\n",
       "      <td>4.249880</td>\n",
       "      <td>1.878509</td>\n",
       "      <td>-1.843684</td>\n",
       "      <td>0.590616</td>\n",
       "      <td>4.322959</td>\n",
       "      <td>1.758719</td>\n",
       "      <td>-0.496756</td>\n",
       "      <td>0.102398</td>\n",
       "      <td>2.106064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756345</td>\n",
       "      <td>-0.927378</td>\n",
       "      <td>1.059688</td>\n",
       "      <td>0.985793</td>\n",
       "      <td>2.137273</td>\n",
       "      <td>1.898203</td>\n",
       "      <td>-1.014003</td>\n",
       "      <td>0.260052</td>\n",
       "      <td>-1.097170</td>\n",
       "      <td>-0.087865</td>\n",
       "      <td>-1.188472</td>\n",
       "      <td>-0.022678</td>\n",
       "      <td>-1.142896</td>\n",
       "      <td>-0.167176</td>\n",
       "      <td>-1.190245</td>\n",
       "      <td>-0.064134</td>\n",
       "      <td>-0.797047</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>14.509829</td>\n",
       "      <td>-2.720398</td>\n",
       "      <td>-3.096805</td>\n",
       "      <td>-14.735178</td>\n",
       "      <td>7.062516</td>\n",
       "      <td>9.129021</td>\n",
       "      <td>-1.019804</td>\n",
       "      <td>-0.561736</td>\n",
       "      <td>-11.715749</td>\n",
       "      <td>5.661101</td>\n",
       "      <td>10.529041</td>\n",
       "      <td>-0.794238</td>\n",
       "      <td>-0.117977</td>\n",
       "      <td>-10.067919</td>\n",
       "      <td>5.718981</td>\n",
       "      <td>11.330316</td>\n",
       "      <td>-0.986966</td>\n",
       "      <td>-0.073897</td>\n",
       "      <td>-12.394593</td>\n",
       "      <td>6.392561</td>\n",
       "      <td>9.827934</td>\n",
       "      <td>-0.900262</td>\n",
       "      <td>-0.792176</td>\n",
       "      <td>-12.286801</td>\n",
       "      <td>6.349526</td>\n",
       "      <td>14.770886</td>\n",
       "      <td>-1.794175</td>\n",
       "      <td>-2.463012</td>\n",
       "      <td>-14.211164</td>\n",
       "      <td>7.030447</td>\n",
       "      <td>4.634613</td>\n",
       "      <td>17.386347</td>\n",
       "      <td>2.935177</td>\n",
       "      <td>2.075944</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>1.955968</td>\n",
       "      <td>2.982250</td>\n",
       "      <td>11.521006</td>\n",
       "      <td>1.084270</td>\n",
       "      <td>0.017147</td>\n",
       "      <td>11.286276</td>\n",
       "      <td>2.835078</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>9.559752</td>\n",
       "      <td>1.941535</td>\n",
       "      <td>0.024763</td>\n",
       "      <td>10.252970</td>\n",
       "      <td>1.519290</td>\n",
       "      <td>0.007987</td>\n",
       "      <td>8.452340</td>\n",
       "      <td>2.845063</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>14.169703</td>\n",
       "      <td>2.335570</td>\n",
       "      <td>0.017561</td>\n",
       "      <td>18.792925</td>\n",
       "      <td>4.343699</td>\n",
       "      <td>0.085589</td>\n",
       "      <td>30.027344</td>\n",
       "      <td>26.027344</td>\n",
       "      <td>26.019531</td>\n",
       "      <td>40.039062</td>\n",
       "      <td>26.023438</td>\n",
       "      <td>15.078125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.007812</td>\n",
       "      <td>8.003906</td>\n",
       "      <td>14.011719</td>\n",
       "      <td>11.003906</td>\n",
       "      <td>3.09375</td>\n",
       "      <td>5.640157e+09</td>\n",
       "      <td>-5.426431e+09</td>\n",
       "      <td>-6.850926e+08</td>\n",
       "      <td>-9.404832e+08</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>2.708821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>730</td>\n",
       "      <td>-61.548219</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>42</td>\n",
       "      <td>1.818030</td>\n",
       "      <td>3.128522</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.157576</td>\n",
       "      <td>0.157576</td>\n",
       "      <td>0.157576</td>\n",
       "      <td>0.154545</td>\n",
       "      <td>0.154545</td>\n",
       "      <td>0.157576</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>47.310059</td>\n",
       "      <td>2.112415</td>\n",
       "      <td>24.131868</td>\n",
       "      <td>20.994711</td>\n",
       "      <td>0.081988</td>\n",
       "      <td>3.811045</td>\n",
       "      <td>0.069697</td>\n",
       "      <td>47.310059</td>\n",
       "      <td>-19.159811</td>\n",
       "      <td>2.267434</td>\n",
       "      <td>0.409172</td>\n",
       "      <td>3.177854</td>\n",
       "      <td>4.196749</td>\n",
       "      <td>78.773438</td>\n",
       "      <td>2.964844</td>\n",
       "      <td>2.972656</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.249057</td>\n",
       "      <td>748.253238</td>\n",
       "      <td>680.616684</td>\n",
       "      <td>13.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.936685</td>\n",
       "      <td>3.461790</td>\n",
       "      <td>4.729538</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.200752</td>\n",
       "      <td>7.334944</td>\n",
       "      <td>13.515895</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.133676</td>\n",
       "      <td>124.845250</td>\n",
       "      <td>119.500255</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>1.149667</td>\n",
       "      <td>168.280524</td>\n",
       "      <td>162.799417</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>1.309389</td>\n",
       "      <td>219.745132</td>\n",
       "      <td>202.532898</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>1.307157</td>\n",
       "      <td>231.509178</td>\n",
       "      <td>199.286369</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>1.813163</td>\n",
       "      <td>1.046502e+05</td>\n",
       "      <td>5.989138</td>\n",
       "      <td>4.124452e+03</td>\n",
       "      <td>5.480405</td>\n",
       "      <td>4.196749</td>\n",
       "      <td>29.315018</td>\n",
       "      <td>25.373110</td>\n",
       "      <td>2.619698</td>\n",
       "      <td>5.041308</td>\n",
       "      <td>4.134364</td>\n",
       "      <td>-2.098943</td>\n",
       "      <td>-0.102671</td>\n",
       "      <td>3.692219</td>\n",
       "      <td>2.832126</td>\n",
       "      <td>5.221543</td>\n",
       "      <td>-2.250251</td>\n",
       "      <td>2.679523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253669</td>\n",
       "      <td>0.171545</td>\n",
       "      <td>1.487815</td>\n",
       "      <td>0.053560</td>\n",
       "      <td>2.359559</td>\n",
       "      <td>3.253634</td>\n",
       "      <td>0.474215</td>\n",
       "      <td>0.356910</td>\n",
       "      <td>0.976374</td>\n",
       "      <td>0.471342</td>\n",
       "      <td>5.131290</td>\n",
       "      <td>2.385066</td>\n",
       "      <td>7.125666</td>\n",
       "      <td>2.662075</td>\n",
       "      <td>6.081065</td>\n",
       "      <td>2.537802</td>\n",
       "      <td>3.583130</td>\n",
       "      <td>1.680352</td>\n",
       "      <td>5.942166</td>\n",
       "      <td>-0.048080</td>\n",
       "      <td>0.024093</td>\n",
       "      <td>-3.459960</td>\n",
       "      <td>1.816127</td>\n",
       "      <td>5.693109</td>\n",
       "      <td>0.141057</td>\n",
       "      <td>0.171335</td>\n",
       "      <td>-3.393080</td>\n",
       "      <td>1.789767</td>\n",
       "      <td>20.994711</td>\n",
       "      <td>2.400870</td>\n",
       "      <td>0.491791</td>\n",
       "      <td>-2.848838</td>\n",
       "      <td>5.505767</td>\n",
       "      <td>33.572102</td>\n",
       "      <td>3.236164</td>\n",
       "      <td>0.660402</td>\n",
       "      <td>-5.435799</td>\n",
       "      <td>8.112836</td>\n",
       "      <td>41.159981</td>\n",
       "      <td>4.308728</td>\n",
       "      <td>1.004354</td>\n",
       "      <td>-5.836310</td>\n",
       "      <td>10.604821</td>\n",
       "      <td>47.310059</td>\n",
       "      <td>4.539396</td>\n",
       "      <td>2.542647</td>\n",
       "      <td>-19.159811</td>\n",
       "      <td>13.201397</td>\n",
       "      <td>12.301396</td>\n",
       "      <td>39.955154</td>\n",
       "      <td>4.227614</td>\n",
       "      <td>2.431124</td>\n",
       "      <td>0.017004</td>\n",
       "      <td>3.124890</td>\n",
       "      <td>5.339545</td>\n",
       "      <td>27.859081</td>\n",
       "      <td>8.115680</td>\n",
       "      <td>0.547215</td>\n",
       "      <td>6.123136</td>\n",
       "      <td>1.744857</td>\n",
       "      <td>0.017004</td>\n",
       "      <td>5.713929</td>\n",
       "      <td>1.485067</td>\n",
       "      <td>0.112996</td>\n",
       "      <td>20.706535</td>\n",
       "      <td>1.279887</td>\n",
       "      <td>0.046416</td>\n",
       "      <td>32.369781</td>\n",
       "      <td>2.275236</td>\n",
       "      <td>0.059754</td>\n",
       "      <td>46.211815</td>\n",
       "      <td>2.600007</td>\n",
       "      <td>0.010972</td>\n",
       "      <td>60.048317</td>\n",
       "      <td>6.930541</td>\n",
       "      <td>0.020015</td>\n",
       "      <td>1.023438</td>\n",
       "      <td>9.968750</td>\n",
       "      <td>78.773438</td>\n",
       "      <td>72.792969</td>\n",
       "      <td>78.773438</td>\n",
       "      <td>69.812500</td>\n",
       "      <td>1.023438</td>\n",
       "      <td>9.968750</td>\n",
       "      <td>60.820312</td>\n",
       "      <td>41.890625</td>\n",
       "      <td>47.871094</td>\n",
       "      <td>57.84375</td>\n",
       "      <td>8.839063e+06</td>\n",
       "      <td>-5.268061e+06</td>\n",
       "      <td>2.190031e+05</td>\n",
       "      <td>2.660137e+05</td>\n",
       "      <td>0.471342</td>\n",
       "      <td>2.805885e+06</td>\n",
       "      <td>3.259617e+07</td>\n",
       "      <td>-4.423077e+06</td>\n",
       "      <td>3.727567e+06</td>\n",
       "      <td>763548.915109</td>\n",
       "      <td>2.385066</td>\n",
       "      <td>8.631597e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  object_id      gal_b  hostgal_photoz  hostgal_photoz_err  target  \\\n",
       "0      0        615 -51.753706          0.0000              0.0000      92   \n",
       "1      1        713 -54.460748          1.6267              0.2552      88   \n",
       "2      2        730 -61.548219          0.2262              0.0157      42   \n",
       "\n",
       "   haversine   latlon1  diff_hostgal  diff_hostgal_abs  \\\n",
       "0   0.319006 -1.528827        0.0000            0.0000   \n",
       "1   1.698939  3.258921        0.1914            0.1914   \n",
       "2   1.818030  3.128522        0.0058            0.0058   \n",
       "\n",
       "   passband_0_ratio_detect  passband_1_ratio_detect  passband_2_ratio_detect  \\\n",
       "0                 0.162162                 0.168168                 0.171171   \n",
       "1                 0.166667                 0.250000                 0.250000   \n",
       "2                 0.000000                 0.000000                 0.304348   \n",
       "\n",
       "   passband_3_ratio_detect  passband_4_ratio_detect  passband_5_ratio_detect  \\\n",
       "0                 0.171171                 0.171171                 0.156156   \n",
       "1                 0.250000                 0.083333                 0.000000   \n",
       "2                 0.304348                 0.217391                 0.173913   \n",
       "\n",
       "   passband_0_ratio  passband_1_ratio  passband_2_ratio  passband_3_ratio  \\\n",
       "0          0.178977          0.164773          0.164773          0.164773   \n",
       "1          0.200000          0.160000          0.160000          0.160000   \n",
       "2          0.218182          0.157576          0.157576          0.157576   \n",
       "\n",
       "   passband_4_ratio  passband_5_ratio  ratio_by_band_median  \\\n",
       "0          0.164773          0.161932              0.164773   \n",
       "1          0.160000          0.160000              0.160000   \n",
       "2          0.154545          0.154545              0.157576   \n",
       "\n",
       "   ratio_by_band_var  flux_max_detected  flux_min_detected  \\\n",
       "0           0.000038         660.626343       -1100.440063   \n",
       "1           0.000267          11.330316         -12.394593   \n",
       "2           0.000639          47.310059           2.112415   \n",
       "\n",
       "   flux_mean_detected  flux_median_detected  flux_skew_detected  \\\n",
       "0         -130.266769           -102.768921           -0.291382   \n",
       "1           -6.061436             -8.975166            1.308961   \n",
       "2           24.131868             20.994711            0.081988   \n",
       "\n",
       "   flux_max_min_detected  flux_max    flux_min    flux_mean  flux_median  \\\n",
       "0               7.473675  0.946023  660.626343 -1100.440063  -123.097000   \n",
       "1               3.166525  0.171429   14.770886   -14.735178    -1.423351   \n",
       "2               3.811045  0.069697   47.310059   -19.159811     2.267434   \n",
       "\n",
       "   flux_skew  flux_max_min  detected_mean    mjd_diff  mjd_halfflux  \\\n",
       "0 -89.477524     -0.349540       7.473675  873.792969      0.015625   \n",
       "1  -0.873032      0.014989       3.384596  846.800781      3.042969   \n",
       "2   0.409172      3.177854       4.196749   78.773438      2.964844   \n",
       "\n",
       "   mjd_sixthflux  diff_baba_mjd  max_flux_0_1  \\\n",
       "0      13.996094      13.980469   -535.443542   \n",
       "1       3.042969       0.000000      5.380808   \n",
       "2       2.972656       0.007812      0.249057   \n",
       "\n",
       "   flux__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0                                43330.143254   \n",
       "1                                  498.172763   \n",
       "2                                  748.253238   \n",
       "\n",
       "   flux__fft_coefficient__coeff_1__attr_\"abs\"  \\\n",
       "0                                15303.668045   \n",
       "1                                 1258.252791   \n",
       "2                                  680.616684   \n",
       "\n",
       "   flux__longest_strike_above_mean  flux__number_crossing_m__m_1      symm  \\\n",
       "0                             19.0                          61.0  0.985612   \n",
       "1                             50.0                          47.0  0.986149   \n",
       "2                             13.0                         113.0  0.936685   \n",
       "\n",
       "   0__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0                               205.036927   \n",
       "1                               190.427854   \n",
       "2                                 3.461790   \n",
       "\n",
       "   0__fft_coefficient__coeff_1__attr_\"abs\"  0__longest_strike_above_mean  \\\n",
       "0                              1628.427737                           5.0   \n",
       "1                               299.586560                          33.0   \n",
       "2                                 4.729538                           6.0   \n",
       "\n",
       "   0__number_crossing_m__m_1  0__ratio_beyond_r_sigma__r_0.5  \\\n",
       "0                       18.0                        0.793651   \n",
       "1                        9.0                        0.757143   \n",
       "2                       27.0                        0.666667   \n",
       "\n",
       "   0__sample_entropy  1__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0           2.016440                             22370.594833   \n",
       "1           2.179983                                57.109049   \n",
       "2           2.200752                                 7.334944   \n",
       "\n",
       "   1__fft_coefficient__coeff_1__attr_\"abs\"  1__longest_strike_above_mean  \\\n",
       "0                              2806.374162                           2.0   \n",
       "1                               192.539230                          15.0   \n",
       "2                                13.515895                           5.0   \n",
       "\n",
       "   1__number_crossing_m__m_1  1__ratio_beyond_r_sigma__r_0.5  \\\n",
       "0                       21.0                        0.793103   \n",
       "1                        7.0                        0.678571   \n",
       "2                       17.0                        0.500000   \n",
       "\n",
       "   1__sample_entropy  2__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0           1.933884                              7780.500810   \n",
       "1           2.335591                                44.477326   \n",
       "2           2.133676                               124.845250   \n",
       "\n",
       "   2__fft_coefficient__coeff_1__attr_\"abs\"  2__longest_strike_above_mean  \\\n",
       "0                              2805.598110                           2.0   \n",
       "1                               191.057527                          20.0   \n",
       "2                               119.500255                           9.0   \n",
       "\n",
       "   2__number_crossing_m__m_1  2__ratio_beyond_r_sigma__r_0.5  \\\n",
       "0                       25.0                        0.741379   \n",
       "1                        7.0                        0.767857   \n",
       "2                       17.0                        0.480769   \n",
       "\n",
       "   2__sample_entropy  3__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0           1.959309                              7024.003069   \n",
       "1           2.124602                                55.270115   \n",
       "2           1.149667                               168.280524   \n",
       "\n",
       "   3__fft_coefficient__coeff_1__attr_\"abs\"  3__longest_strike_above_mean  \\\n",
       "0                              2536.068845                           3.0   \n",
       "1                               212.522263                          20.0   \n",
       "2                               162.799417                           9.0   \n",
       "\n",
       "   3__number_crossing_m__m_1  3__ratio_beyond_r_sigma__r_0.5  \\\n",
       "0                       25.0                        0.758621   \n",
       "1                        9.0                        0.767857   \n",
       "2                       18.0                        0.403846   \n",
       "\n",
       "   3__sample_entropy  4__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0           1.861271                              3245.366350   \n",
       "1           2.146581                                50.414646   \n",
       "2           1.309389                               219.745132   \n",
       "\n",
       "   4__fft_coefficient__coeff_1__attr_\"abs\"  4__longest_strike_above_mean  \\\n",
       "0                              2741.539788                           5.0   \n",
       "1                               203.892482                          19.0   \n",
       "2                               202.532898                           9.0   \n",
       "\n",
       "   4__number_crossing_m__m_1  4__ratio_beyond_r_sigma__r_0.5  \\\n",
       "0                       23.0                        0.775862   \n",
       "1                        7.0                        0.821429   \n",
       "2                       19.0                        0.372549   \n",
       "\n",
       "   4__sample_entropy  5__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0           1.921409                              2704.641263   \n",
       "1           2.221544                               100.473774   \n",
       "2           1.307157                               231.509178   \n",
       "\n",
       "   5__fft_coefficient__coeff_1__attr_\"abs\"  5__longest_strike_above_mean  \\\n",
       "0                              2893.344216                           5.0   \n",
       "1                               143.963093                           8.0   \n",
       "2                               199.286369                           7.0   \n",
       "\n",
       "   5__number_crossing_m__m_1  5__ratio_beyond_r_sigma__r_0.5  \\\n",
       "0                       23.0                        0.771930   \n",
       "1                       15.0                        0.732143   \n",
       "2                       20.0                        0.431373   \n",
       "\n",
       "   5__sample_entropy  flux_ratio_sq_sum  flux_ratio_sq_skew  \\\n",
       "0           1.886318      -9.601766e+08           -1.414322   \n",
       "1           2.302585      -2.875087e+04           -3.454554   \n",
       "2           1.813163       1.046502e+05            5.989138   \n",
       "\n",
       "   flux_by_flux_ratio_sq_sum  flux_by_flux_ratio_sq_skew  flux_dif  flux_dif2  \\\n",
       "0               2.929669e+06                    0.812722  7.473675 -14.306331   \n",
       "1               5.886068e+03                    3.439423  3.384596 -20.730003   \n",
       "2               4.124452e+03                    5.480405  4.196749  29.315018   \n",
       "\n",
       "   flux_w_mean  flux_dif3  flux_max__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0  -327.742340  -5.373326                                        7.864678   \n",
       "1    -4.884563  -6.040676                                        4.249880   \n",
       "2    25.373110   2.619698                                        5.041308   \n",
       "\n",
       "   flux_max__fft_coefficient__coeff_1__attr_\"abs\"  flux_max__kurtosis  \\\n",
       "0                                        6.281597            0.314536   \n",
       "1                                        1.878509           -1.843684   \n",
       "2                                        4.134364           -2.098943   \n",
       "\n",
       "   flux_max__skewness  flux_min__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0           -0.527777                                        8.094029   \n",
       "1            0.590616                                        4.322959   \n",
       "2           -0.102671                                        3.692219   \n",
       "\n",
       "   flux_min__fft_coefficient__coeff_1__attr_\"abs\"  flux_min__kurtosis  \\\n",
       "0                                        6.729821            1.487434   \n",
       "1                                        1.758719           -0.496756   \n",
       "2                                        2.832126            5.221543   \n",
       "\n",
       "   flux_min__skewness  flux_mean__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0           -0.763272                                         6.616880   \n",
       "1            0.102398                                         2.106064   \n",
       "2           -2.250251                                         2.679523   \n",
       "\n",
       "        ...         flux_err_rate_min  flux_err_rate_mean  \\\n",
       "0       ...                 -3.925288           -4.159871   \n",
       "1       ...                 -0.756345           -0.927378   \n",
       "2       ...                  0.253669            0.171545   \n",
       "\n",
       "   flux_err_rate_median  flux_err_rate_var  flux_err_rate_skew  \\\n",
       "0              1.146181           1.219583            2.371641   \n",
       "1              1.059688           0.985793            2.137273   \n",
       "2              1.487815           0.053560            2.359559   \n",
       "\n",
       "   flux_err_rate_max_min  0__kurtosis  0__skewness  1__kurtosis  1__skewness  \\\n",
       "0               1.203312    -1.475181     0.128917    -1.255123     0.415581   \n",
       "1               1.898203    -1.014003     0.260052    -1.097170    -0.087865   \n",
       "2               3.253634     0.474215     0.356910     0.976374     0.471342   \n",
       "\n",
       "   2__kurtosis  2__skewness  3__kurtosis  3__skewness  4__kurtosis  \\\n",
       "0    -1.409885     0.339918    -1.449858     0.293128    -1.548319   \n",
       "1    -1.188472    -0.022678    -1.142896    -0.167176    -1.190245   \n",
       "2     5.131290     2.385066     7.125666     2.662075     6.081065   \n",
       "\n",
       "   4__skewness  5__kurtosis  5__skewness  0__maximum   0__mean  0__median  \\\n",
       "0     0.200096    -1.592820     0.125269  125.182808 -3.254554 -10.015225   \n",
       "1    -0.064134    -0.797047     0.218182   14.509829 -2.720398  -3.096805   \n",
       "2     2.537802     3.583130     1.680352    5.942166 -0.048080   0.024093   \n",
       "\n",
       "   0__minimum  0__standard_deviation  1__maximum     1__mean   1__median  \\\n",
       "0 -116.913223              83.275841  660.626343 -385.699921 -488.057983   \n",
       "1  -14.735178               7.062516    9.129021   -1.019804   -0.561736   \n",
       "2   -3.459960               1.816127    5.693109    0.141057    0.171335   \n",
       "\n",
       "    1__minimum  1__standard_deviation  2__maximum     2__mean   2__median  \\\n",
       "0 -1100.440063             596.576904  611.984558 -134.146576 -265.686005   \n",
       "1   -11.715749               5.661101   10.529041   -0.794238   -0.117977   \n",
       "2    -3.393080               1.789767   20.994711    2.400870    0.491791   \n",
       "\n",
       "   2__minimum  2__standard_deviation  3__maximum     3__mean   3__median  \\\n",
       "0 -681.858887             451.180817  445.737061 -121.103500 -162.170944   \n",
       "1  -10.067919               5.718981   11.330316   -0.986966   -0.073897   \n",
       "2   -2.848838               5.505767   33.572102    3.236164    0.660402   \n",
       "\n",
       "   3__minimum  3__standard_deviation  4__maximum    4__mean   4__median  \\\n",
       "0 -530.644592             332.520874  381.953735 -55.954590 -103.541367   \n",
       "1  -12.394593               6.392561    9.827934  -0.900262   -0.792176   \n",
       "2   -5.435799               8.112836   41.159981   4.308728    1.004354   \n",
       "\n",
       "   4__minimum  4__standard_deviation  5__maximum    5__mean  5__median  \\\n",
       "0 -422.184509             289.276978  378.188141 -47.449844 -85.524307   \n",
       "1  -12.286801               6.349526   14.770886  -1.794175  -2.463012   \n",
       "2   -5.836310              10.604821   47.310059   4.539396   2.542647   \n",
       "\n",
       "   5__minimum  5__standard_deviation  diff_flux__kurtosis_diff  \\\n",
       "0 -422.815094             292.182281                  1.561865   \n",
       "1  -14.211164               7.030447                  4.634613   \n",
       "2  -19.159811              13.201397                 12.301396   \n",
       "\n",
       "   diff_flux__maximum_diff  diff_flux__mean_diff  diff_flux__median_diff  \\\n",
       "0              1007.002441            202.114075              107.974808   \n",
       "1                17.386347              2.935177                2.075944   \n",
       "2                39.955154              4.227614                2.431124   \n",
       "\n",
       "   diff_flux__minimum_diff  diff_flux__skewness_diff  \\\n",
       "0                 0.076019                  1.432323   \n",
       "1                 0.004893                  1.955968   \n",
       "2                 0.017004                  3.124890   \n",
       "\n",
       "   diff_flux__standard_deviation_diff  diff_flux__maximum_diff_det  \\\n",
       "0                          210.771271                  1007.002441   \n",
       "1                            2.982250                    11.521006   \n",
       "2                            5.339545                    27.859081   \n",
       "\n",
       "   diff_flux__median_diff_det  diff_flux__minimum_diff_det  0__maximum_diff  \\\n",
       "0                  126.217438                     0.076019       191.556000   \n",
       "1                    1.084270                     0.017147        11.286276   \n",
       "2                    8.115680                     0.547215         6.123136   \n",
       "\n",
       "   0__median_diff  0__minimum_diff  1__maximum_diff  1__median_diff  \\\n",
       "0       39.526798         0.170685      1745.011963      573.419739   \n",
       "1        2.835078         0.004893         9.559752        1.941535   \n",
       "2        1.744857         0.017004         5.713929        1.485067   \n",
       "\n",
       "   1__minimum_diff  2__maximum_diff  2__median_diff  2__minimum_diff  \\\n",
       "0         4.854187      1280.468140      412.171204         6.889648   \n",
       "1         0.024763        10.252970        1.519290         0.007987   \n",
       "2         0.112996        20.706535        1.279887         0.046416   \n",
       "\n",
       "   3__maximum_diff  3__median_diff  3__minimum_diff  4__maximum_diff  \\\n",
       "0       879.547913      347.493164         1.488678       767.241089   \n",
       "1         8.452340        2.845063         0.155172        14.169703   \n",
       "2        32.369781        2.275236         0.059754        46.211815   \n",
       "\n",
       "   4__median_diff  4__minimum_diff  5__maximum_diff  5__median_diff  \\\n",
       "0      252.360184         4.495239       734.515442      214.830948   \n",
       "1        2.335570         0.017561        18.792925        4.343699   \n",
       "2        2.600007         0.010972        60.048317        6.930541   \n",
       "\n",
       "   5__minimum_diff  sixth_band_0  sixth_band_1  sixth_band_2  sixth_band_3  \\\n",
       "0         5.912170      3.011719    241.230469    241.230469     16.023438   \n",
       "1         0.085589     30.027344     26.027344     26.019531     40.039062   \n",
       "2         0.020015      1.023438      9.968750     78.773438     72.792969   \n",
       "\n",
       "   sixth_band_4  sixth_band_5  second_band_0  second_band_1  second_band_2  \\\n",
       "0      3.003906      3.000000       2.003906     241.230469     241.230469   \n",
       "1     26.023438     15.078125       1.000000      17.007812       8.003906   \n",
       "2     78.773438     69.812500       1.023438       9.968750      60.820312   \n",
       "\n",
       "   second_band_3  second_band_4  second_band_5  band_0_flux_max  \\\n",
       "0      13.054688       3.003906        3.00000     1.251828e+02   \n",
       "1      14.011719      11.003906        3.09375     5.640157e+09   \n",
       "2      41.890625      47.871094       57.84375     8.839063e+06   \n",
       "\n",
       "   band_0_flux_min  band_0_flux_mean  band_0_flux_med  band_0_flux_skew  \\\n",
       "0    -1.169132e+02     -3.254554e+00    -1.001523e+01          0.128917   \n",
       "1    -5.426431e+09     -6.850926e+08    -9.404832e+08          0.218182   \n",
       "2    -5.268061e+06      2.190031e+05     2.660137e+05          0.471342   \n",
       "\n",
       "   band_0_flux_std  band_1_flux_max  band_1_flux_min  band_1_flux_mean  \\\n",
       "0     8.394473e+01     6.606263e+02    -1.100440e+03     -2.599232e+02   \n",
       "1     2.708821e+09              NaN              NaN               NaN   \n",
       "2     2.805885e+06     3.259617e+07    -4.423077e+06      3.727567e+06   \n",
       "\n",
       "   band_1_flux_med  band_1_flux_skew  band_1_flux_std  \n",
       "0      -349.215576          0.185580     5.460072e+02  \n",
       "1              NaN               NaN              NaN  \n",
       "2    763548.915109          2.385066     8.631597e+06  \n",
       "\n",
       "[3 rows x 219 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ex_gal.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ex_gal['max_fix_flux_diff_0_1'] = train_ex_gal['band_0_flux_max'] - train_ex_gal['band_1_flux_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ex_gal['max_fix_flux_diff_0_1'] = test_ex_gal['band_0_flux_max'] - test_ex_gal['band_1_flux_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null(data):\n",
    "    print(data.isnull().sum())\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "#print(len(train_extra_galaxy))\n",
    "#print(len(test_extra_galaxy))\n",
    "#print(check_null(train_gal))\n",
    "#print(check_null(train_oof_summary))\n",
    "#print(check_null(test_oof_summary))\n",
    "#print(check_null(train_ex_gal))\n",
    "#print(check_null(test_ex_gal))\n",
    "#print(check_null(test_gal))\n",
    "#print(check_null(test_extra_galaxy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop more feature\n",
    "drop_list = ['0__minimum_diff','1__minimum_diff','2__minimum_diff','3__minimum_diff','4__minimum_diff','5__minimum_diff'\n",
    "             ,'diff_flux__minimum_diff','diff_flux__minimum_diff_det','index','flux_dif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ex_gal = train_ex_gal.drop(drop_list,axis=1)\n",
    "test_ex_gal = test_ex_gal.drop(drop_list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gal = train_gal.replace([np.inf, -np.inf], np.nan)\n",
    "train_ex_gal = train_ex_gal.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "train_gal_mean = train_gal.mean(axis=0)\n",
    "train_ex_gal_mean = train_ex_gal.mean(axis=0)\n",
    "\n",
    "train_gal.fillna(train_gal_mean, inplace=True)\n",
    "train_ex_gal.fillna(train_ex_gal_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add mean → good result\n",
    "\n",
    "test_gal = test_gal.replace([np.inf, -np.inf], np.nan)\n",
    "test_ex_gal = test_ex_gal.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "test_gal = test_gal.fillna(train_gal_mean)\n",
    "test_ex_gal = test_ex_gal.fillna(train_ex_gal_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7848, 167) 行×列\n",
      "train_gal:使用メモリ 0.01 GB\n",
      "(7848, 210) 行×列\n",
      "train_gal:使用メモリ 0.01 GB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# check used_momery\n",
    "print(train_gal.shape,\"行×列\")\n",
    "print(\"train_gal:使用メモリ\",round(sys.getsizeof(train_gal) / 1073741824,2),\"GB\")\n",
    "\n",
    "print(train_ex_gal.shape,\"行×列\")\n",
    "print(\"train_gal:使用メモリ\",round(sys.getsizeof(train_ex_gal) / 1073741824,2),\"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3492890, 166) 行×列\n",
      "test:使用メモリ 3.92 GB\n",
      "(3492890, 209) 行×列\n",
      "test:使用メモリ 4.89 GB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# check used_momery\n",
    "print(test_gal.shape,\"行×列\")\n",
    "print(\"test:使用メモリ\",round(sys.getsizeof(test_gal) / 1073741824,2),\"GB\")\n",
    "\n",
    "print(test_ex_gal.shape,\"行×列\")\n",
    "print(\"test:使用メモリ\",round(sys.getsizeof(test_ex_gal) / 1073741824,2),\"GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split galaxica\n",
    "train_galaxy = train_gal[train_gal['hostgal_photoz'] == 0]\n",
    "train_extra_galaxy = train_ex_gal[train_ex_gal['hostgal_photoz'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_galaxy = test_gal[test_gal['hostgal_photoz'] == 0]\n",
    "test_extra_galaxy = test_ex_gal[test_ex_gal['hostgal_photoz'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gal_y = train_galaxy['target']\n",
    "ex_gal_y = train_extra_galaxy['target']\n",
    "train_gal_id = train_galaxy['object_id']\n",
    "train_ex_gal_id = train_extra_galaxy['object_id']\n",
    "\n",
    "del train_galaxy['target'],train_extra_galaxy['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_extra_galaxy['object_id'],train_galaxy['object_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gal_id = test_galaxy['object_id']\n",
    "test_ex_gal_id = test_extra_galaxy['object_id']\n",
    "del test_galaxy['object_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_extra_galaxy['object_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary val_galaxy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "target_enc = OneHotEncoder()\n",
    "gal_X = target_enc.fit_transform(gal_y.values.reshape(-1,1)).toarray()\n",
    "ex_gal_X = target_enc.fit_transform(ex_gal_y.values.reshape(-1,1)).toarray()\n",
    "gal_class_binary = pd.DataFrame(gal_X, columns = [\"target_6\",\"target_16\",\"target_53\",\"target_65\",\"target_92\"])\n",
    "ex_gal_class_binary = pd.DataFrame(ex_gal_X, columns = [\"target_15\",\"target_42\",\"target_52\",\"target_62\",\"target_64\",\"target_67\",\"target_88\",\"target_90\",\"target_95\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_classifiers(full_train=None, y=None, seed=1):\n",
    "\n",
    "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    clfs = []\n",
    "    logloss = []\n",
    "    importances = pd.DataFrame()\n",
    "    # conclusion:defalut is great!\n",
    "    lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        #'num_class': 14,\n",
    "        'metric': 'logloss', #1214 change logloss\n",
    "        'learning_rate': 0.005, #def:0.03\n",
    "        'subsample': .8, #def:.8\n",
    "        'colsample_bytree': .7, #def:.7\n",
    "        'reg_alpha': .01, #def:.01 \n",
    "        'reg_lambda': .01, #def:.01 \n",
    "        'min_split_gain': 0.01, #def:0.01\n",
    "        'min_child_weight': 10, # def:10\n",
    "        'n_estimators': 100000,\n",
    "        'silent': -1,\n",
    "        'verbose': -1,\n",
    "        'max_depth': 7,\n",
    "        #'sample_pos_weight':pos_weight\n",
    "    }\n",
    "    \n",
    "    oof_preds = np.zeros((len(full_train), np.unique(y).shape[0]))\n",
    "    \n",
    "    # photoz_split\n",
    "    target_photoz = pd.cut(full_train.hostgal_photoz, 10)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(target_photoz)\n",
    "    target_photoz = le.transform(target_photoz) \n",
    "    \n",
    "    #for fold_, (trn_, val_) in enumerate(folds.split(y, y)):\n",
    "    for fold_, (trn_, val_) in enumerate(folds.split(target_photoz, target_photoz)):    \n",
    "        trn_x, trn_y = full_train.iloc[trn_], y.iloc[trn_]\n",
    "        val_x, val_y = full_train.iloc[val_], y.iloc[val_]\n",
    "\n",
    "        clf = lgb.LGBMClassifier(**lgb_params)\n",
    "        clf.fit(\n",
    "            trn_x, trn_y,\n",
    "            eval_set=[(trn_x, trn_y), (val_x, val_y)],\n",
    "            #eval_metric=lgb_multi_weighted_logloss,\n",
    "            eval_metric='binary_logloss',\n",
    "            verbose=2000,\n",
    "            early_stopping_rounds=100,\n",
    "            #sample_weight=trn_y.map(weights)\n",
    "            #callbacks=[lgb.reset_parameter(max_depth=[4] * 100 + [2] * 300 + [1] * 3600)]\n",
    "            #callbacks=[lgb.reset_parameter(\n",
    "            #    learning_rate=[0.01] * 100 + [0.03] * 1000 + [0.05] * 2900\n",
    "            #    ,max_depth=[5] * 100 + [3] * 1000 + [2] * 2900\n",
    "            #)]\n",
    "        )\n",
    "        oof_preds[val_, :] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)\n",
    "        #get_logger().info(multi_weighted_logloss(val_y, clf.predict_proba(val_x, num_iteration=clf.best_iteration_)))\n",
    "\n",
    "        imp_df = pd.DataFrame()\n",
    "        imp_df['feature'] = full_train.columns\n",
    "        imp_df['gain'] = clf.feature_importances_\n",
    "        imp_df['fold'] = fold_ + 1\n",
    "        importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "\n",
    "        clfs.append(clf)\n",
    "    \n",
    "    logloss = log_loss(y, oof_preds)\n",
    "    #fpr, tpr, thresholds = roc_curve(y, oof_preds[:,1], pos_label=1)\n",
    "    print('total_logloss : %.5f ' % logloss)\n",
    "    #auc_class = auc(fpr, tpr)\n",
    "    \n",
    "    return clfs, importances, oof_preds, logloss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def save_importances(importances_,layout=True):\n",
    "    mean_gain = importances_[['gain', 'feature']].groupby('feature').mean()\n",
    "    importances_['mean_gain'] = importances_['feature'].map(mean_gain['gain'])\n",
    "    if layout==True:\n",
    "        plt.figure(figsize=(8, 50))\n",
    "        sns.barplot(x='gain', y='feature', data=importances_.sort_values('mean_gain', ascending=False))\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def galaxy_model(galaxy='gal',pred=False, layout=False, seed_list=[1,2]):\n",
    "    importance_dm = pd.DataFrame()\n",
    "    oof_merge = pd.DataFrame()\n",
    "    preds_merge = pd.DataFrame()\n",
    "    oof_total = pd.DataFrame()\n",
    "    preds_total = pd.DataFrame()\n",
    "    logloss_total = []\n",
    "    \n",
    "    lgb_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    #'num_class': 14,\n",
    "    'metric': 'logloss', #1214 change logloss\n",
    "    'learning_rate': 0.03, #def:0.03\n",
    "    'subsample': .8, #def:.8\n",
    "    'colsample_bytree': .7, #def:.7\n",
    "    'reg_alpha': .01, #def:.01 \n",
    "    'reg_lambda': .01, #def:.01 \n",
    "    'min_split_gain': 0.01, #def:0.01\n",
    "    'min_child_weight': 10, # def:10\n",
    "    'n_estimators': 100000,\n",
    "    'silent': -1,\n",
    "    'verbose': -1,\n",
    "    'max_depth': 3,\n",
    "    }\n",
    "    clf = lgb.LGBMClassifier(**lgb_params)\n",
    "    \n",
    "    # seed averaging\n",
    "    for seed_num in seed_list:\n",
    "        print('------------ seed {} start ------------'.format(seed_num))\n",
    "        \n",
    "        if galaxy=='gal':\n",
    "            for i in range(gal_class_binary.shape[1]):\n",
    "\n",
    "                y = gal_class_binary.iloc[:,i]\n",
    "                \n",
    "                clfs, importances, oof_preds, logloss = train_binary_classifiers(train_galaxy, y, seed_num)\n",
    "                oof_preds = pd.DataFrame(oof_preds[:,1])\n",
    "                save_importances(importances_=importances,layout=layout)\n",
    "                importances = importances[['feature','mean_gain']].drop_duplicates()\n",
    "                importances.columns = ['feature',y.to_frame().columns[0]]\n",
    "\n",
    "                if pred == True:\n",
    "                    preds_ = None\n",
    "                    for clf in tqdm_notebook(clfs):\n",
    "                        if preds_ is None:\n",
    "                            preds_ = clf.predict_proba(test_galaxy) / len(clfs)\n",
    "                        else:\n",
    "                            preds_ += clf.predict_proba(test_galaxy) / len(clfs)\n",
    "                    preds_ = pd.DataFrame(preds_[:,1])\n",
    "\n",
    "                if i == 0:\n",
    "                    importance_dm = importances\n",
    "                    oof_total = oof_preds\n",
    "\n",
    "                    if pred == True:\n",
    "                        preds_total = preds_\n",
    "                else:\n",
    "                    importance_dm = pd.merge(importance_dm,importances,on='feature',how='left')\n",
    "                    oof_total = pd.merge(oof_total,oof_preds,left_index=True,right_index=True) \n",
    "                    if pred == True:\n",
    "                        preds_total = pd.merge(preds_total,preds_,left_index=True,right_index=True)\n",
    "                logloss_total.append(logloss)\n",
    "\n",
    "            oof_total.columns = [\"target_6\",\"target_16\",\"target_53\",\"target_65\",\"target_92\"]\n",
    "\n",
    "            if pred == True:\n",
    "                preds_total.columns = [\"target_6\",\"target_16\",\"target_53\",\"target_65\",\"target_92\"]\n",
    "\n",
    "        if galaxy=='ex_gal':        \n",
    "            for i in range(ex_gal_class_binary.shape[1]):\n",
    "                y = ex_gal_class_binary.iloc[:,i]\n",
    "                \n",
    "                #selector\n",
    "                #lgb_selector = SelectFromModel(clf)\n",
    "                #lgb_selector.fit(train_extra_galaxy, y)\n",
    "                #feature_idx = lgb_selector.get_support() \n",
    "                #feature_name = train_extra_galaxy.columns[feature_idx]\n",
    "\n",
    "                clfs, importances, oof_preds, logloss = train_binary_classifiers(train_extra_galaxy, y, seed_num)\n",
    "\n",
    "                oof_preds = pd.DataFrame(oof_preds[:,1])\n",
    "                save_importances(importances_=importances,layout=layout)\n",
    "                importances = importances[['feature','mean_gain']].drop_duplicates()\n",
    "                importances.columns = ['feature',y.to_frame().columns[0]]\n",
    "\n",
    "                if pred == True:\n",
    "                    preds_ = None\n",
    "\n",
    "                    for clf in tqdm_notebook(clfs):\n",
    "                        if preds_ is None:\n",
    "                            preds_ = clf.predict_proba(test_extra_galaxy) / len(clfs)\n",
    "                        else:\n",
    "                            preds_ += clf.predict_proba(test_extra_galaxy) / len(clfs)\n",
    "\n",
    "                    preds_ = pd.DataFrame(preds_[:,1])\n",
    "\n",
    "                if i == 0:\n",
    "                    importance_dm = importances\n",
    "                    oof_total = oof_preds\n",
    "                    if pred == True:\n",
    "                        preds_total = preds_\n",
    "                else:\n",
    "                    importance_dm = pd.merge(importance_dm,importances,on='feature',how='left')\n",
    "                    oof_total = pd.merge(oof_total,oof_preds,left_index=True,right_index=True) \n",
    "                    if pred == True:\n",
    "                        preds_total = pd.merge(preds_total,preds_,left_index=True,right_index=True)\n",
    "                logloss_total.append(logloss)\n",
    "\n",
    "            oof_total.columns = [\"target_15\",\"target_42\",\"target_52\",\"target_62\",\"target_64\",\"target_67\",\"target_88\",\"target_90\",\"target_95\"]\n",
    "            if pred == True:\n",
    "                preds_total.columns = [\"target_15\",\"target_42\",\"target_52\",\"target_62\",\"target_64\",\"target_67\",\"target_88\",\"target_90\",\"target_95\"]\n",
    "    \n",
    "        # merge seed_result\n",
    "        if seed_num == 1:\n",
    "            oof_merge = oof_total / len(seed_list)\n",
    "            if pred == True:\n",
    "                preds_merge = preds_total / len(seed_list)\n",
    "        else:\n",
    "            oof_merge += oof_total / len(seed_list)\n",
    "            if pred == True:\n",
    "                preds_merge += preds_total / len(seed_list)\n",
    "\n",
    "    if pred == True:    \n",
    "        #return importance_dm,oof_total,preds_total,logloss_total\n",
    "        return importance_dm,oof_merge,preds_merge,logloss_total\n",
    "    else:\n",
    "        #return importance_dm,oof_total,logloss_total\n",
    "        return importance_dm,oof_merge,logloss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------  start gal_model pred  ---------------\n",
      "------------ seed 1 start ------------\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0146161\tvalid_1's binary_logloss: 0.0351148\n",
      "Early stopping, best iteration is:\n",
      "[961]\ttraining's binary_logloss: 0.0146161\tvalid_1's binary_logloss: 0.0351148\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[846]\ttraining's binary_logloss: 0.0144954\tvalid_1's binary_logloss: 0.0354625\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0146415\tvalid_1's binary_logloss: 0.0280187\n",
      "Early stopping, best iteration is:\n",
      "[978]\ttraining's binary_logloss: 0.0146415\tvalid_1's binary_logloss: 0.0280187\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0157181\tvalid_1's binary_logloss: 0.0349502\n",
      "Early stopping, best iteration is:\n",
      "[962]\ttraining's binary_logloss: 0.0157181\tvalid_1's binary_logloss: 0.0349502\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[833]\ttraining's binary_logloss: 0.0153835\tvalid_1's binary_logloss: 0.0555726\n",
      "total_logloss : 0.03782 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58968dc6eaa844238d10e845d77ad6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[630]\ttraining's binary_logloss: 0.0139718\tvalid_1's binary_logloss: 0.039746\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[641]\ttraining's binary_logloss: 0.0134806\tvalid_1's binary_logloss: 0.0327738\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[630]\ttraining's binary_logloss: 0.0132439\tvalid_1's binary_logloss: 0.0364806\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[705]\ttraining's binary_logloss: 0.0134289\tvalid_1's binary_logloss: 0.0236402\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[669]\ttraining's binary_logloss: 0.0130456\tvalid_1's binary_logloss: 0.0440345\n",
      "total_logloss : 0.03534 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5ad6dd7f394857a1d2b385f0b7a1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's binary_logloss: 0.0186759\tvalid_1's binary_logloss: 0.0171776\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[107]\ttraining's binary_logloss: 0.0197236\tvalid_1's binary_logloss: 0.0182755\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[98]\ttraining's binary_logloss: 0.0255409\tvalid_1's binary_logloss: 0.0343083\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[103]\ttraining's binary_logloss: 0.0224742\tvalid_1's binary_logloss: 0.0267565\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[101]\ttraining's binary_logloss: 0.0225492\tvalid_1's binary_logloss: 0.0267664\n",
      "total_logloss : 0.02466 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3370d59482ca41b8a9eb1347413a25cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[653]\ttraining's binary_logloss: 0.0128052\tvalid_1's binary_logloss: 0.0228059\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[618]\ttraining's binary_logloss: 0.0129591\tvalid_1's binary_logloss: 0.0382382\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[662]\ttraining's binary_logloss: 0.0128362\tvalid_1's binary_logloss: 0.0192374\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[673]\ttraining's binary_logloss: 0.0133222\tvalid_1's binary_logloss: 0.0252627\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[621]\ttraining's binary_logloss: 0.0131557\tvalid_1's binary_logloss: 0.0511184\n",
      "total_logloss : 0.03133 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a144d11a4a54718a5c9ab73a13fab34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[226]\ttraining's binary_logloss: 0.0173008\tvalid_1's binary_logloss: 0.0285877\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[236]\ttraining's binary_logloss: 0.0172757\tvalid_1's binary_logloss: 0.0249926\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[220]\ttraining's binary_logloss: 0.0174957\tvalid_1's binary_logloss: 0.030339\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[218]\ttraining's binary_logloss: 0.0176739\tvalid_1's binary_logloss: 0.0387089\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[225]\ttraining's binary_logloss: 0.0171905\tvalid_1's binary_logloss: 0.03058\n",
      "total_logloss : 0.03064 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358f223637ca4091b14b057712ff1a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------  start ex_gal_model pred  ---------------\n",
      "------------ seed 1 start ------------\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[356]\ttraining's binary_logloss: 0.0360528\tvalid_1's binary_logloss: 0.146732\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[430]\ttraining's binary_logloss: 0.0323516\tvalid_1's binary_logloss: 0.112663\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[414]\ttraining's binary_logloss: 0.0322314\tvalid_1's binary_logloss: 0.113195\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttraining's binary_logloss: 0.035321\tvalid_1's binary_logloss: 0.112292\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[453]\ttraining's binary_logloss: 0.0307952\tvalid_1's binary_logloss: 0.116346\n",
      "total_logloss : 0.12028 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be06687aa3d242089db9d78f214e1557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[452]\ttraining's binary_logloss: 0.131151\tvalid_1's binary_logloss: 0.341716\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[650]\ttraining's binary_logloss: 0.102725\tvalid_1's binary_logloss: 0.32512\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[662]\ttraining's binary_logloss: 0.102364\tvalid_1's binary_logloss: 0.30296\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[691]\ttraining's binary_logloss: 0.0984422\tvalid_1's binary_logloss: 0.311352\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[468]\ttraining's binary_logloss: 0.134716\tvalid_1's binary_logloss: 0.288856\n",
      "total_logloss : 0.31406 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff438b1d51e1445e908d6d289118b983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[189]\ttraining's binary_logloss: 0.0572939\tvalid_1's binary_logloss: 0.140633\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[293]\ttraining's binary_logloss: 0.0439301\tvalid_1's binary_logloss: 0.114804\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's binary_logloss: 0.0759401\tvalid_1's binary_logloss: 0.131431\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[353]\ttraining's binary_logloss: 0.0400163\tvalid_1's binary_logloss: 0.0858366\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[202]\ttraining's binary_logloss: 0.0565483\tvalid_1's binary_logloss: 0.114969\n",
      "total_logloss : 0.11757 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc45a85b8c9e4bed88d6e1752e8e8f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[266]\ttraining's binary_logloss: 0.0926742\tvalid_1's binary_logloss: 0.218991\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[352]\ttraining's binary_logloss: 0.0739532\tvalid_1's binary_logloss: 0.203305\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[282]\ttraining's binary_logloss: 0.0890792\tvalid_1's binary_logloss: 0.198076\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[412]\ttraining's binary_logloss: 0.0696298\tvalid_1's binary_logloss: 0.183542\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[355]\ttraining's binary_logloss: 0.0763176\tvalid_1's binary_logloss: 0.180187\n",
      "total_logloss : 0.19686 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d3f4d6b0b046219f13b180f220d2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[562]\ttraining's binary_logloss: 0.00676155\tvalid_1's binary_logloss: 0.0163979\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[576]\ttraining's binary_logloss: 0.00683935\tvalid_1's binary_logloss: 0.0173985\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[482]\ttraining's binary_logloss: 0.00704418\tvalid_1's binary_logloss: 0.023758\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[603]\ttraining's binary_logloss: 0.00672933\tvalid_1's binary_logloss: 0.0159724\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[582]\ttraining's binary_logloss: 0.00691102\tvalid_1's binary_logloss: 0.0178577\n",
      "total_logloss : 0.01828 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ded5d6b1ade4f7e92cb4e4c2b639897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[277]\ttraining's binary_logloss: 0.0408441\tvalid_1's binary_logloss: 0.0999234\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[273]\ttraining's binary_logloss: 0.040561\tvalid_1's binary_logloss: 0.0933843\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[335]\ttraining's binary_logloss: 0.03474\tvalid_1's binary_logloss: 0.0975569\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[251]\ttraining's binary_logloss: 0.0410506\tvalid_1's binary_logloss: 0.114267\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[285]\ttraining's binary_logloss: 0.0388552\tvalid_1's binary_logloss: 0.108673\n",
      "total_logloss : 0.10274 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28af3d4c0a746c084bb922fdd00e91a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[184]\ttraining's binary_logloss: 0.00655337\tvalid_1's binary_logloss: 0.0174031\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[199]\ttraining's binary_logloss: 0.00660881\tvalid_1's binary_logloss: 0.00439414\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[159]\ttraining's binary_logloss: 0.00678619\tvalid_1's binary_logloss: 0.0234121\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[197]\ttraining's binary_logloss: 0.00663707\tvalid_1's binary_logloss: 0.00528497\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[181]\ttraining's binary_logloss: 0.00709975\tvalid_1's binary_logloss: 0.0114123\n",
      "total_logloss : 0.01239 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f4340246204d909312f687f48f50bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[872]\ttraining's binary_logloss: 0.0772249\tvalid_1's binary_logloss: 0.286534\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[854]\ttraining's binary_logloss: 0.0780515\tvalid_1's binary_logloss: 0.328921\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[794]\ttraining's binary_logloss: 0.0885213\tvalid_1's binary_logloss: 0.298572\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0684267\tvalid_1's binary_logloss: 0.25339\n",
      "Early stopping, best iteration is:\n",
      "[1409]\ttraining's binary_logloss: 0.0437542\tvalid_1's binary_logloss: 0.247528\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[838]\ttraining's binary_logloss: 0.0786419\tvalid_1's binary_logloss: 0.280389\n",
      "total_logloss : 0.28843 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8dcf571e3c34f0dace2384ca924d1fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[263]\ttraining's binary_logloss: 0.0138467\tvalid_1's binary_logloss: 0.0297861\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0084041\tvalid_1's binary_logloss: 0.0228241\n",
      "Early stopping, best iteration is:\n",
      "[1423]\ttraining's binary_logloss: 0.00733938\tvalid_1's binary_logloss: 0.0223329\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[368]\ttraining's binary_logloss: 0.0113907\tvalid_1's binary_logloss: 0.0376164\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.00828575\tvalid_1's binary_logloss: 0.0183805\n",
      "Early stopping, best iteration is:\n",
      "[1409]\ttraining's binary_logloss: 0.00725254\tvalid_1's binary_logloss: 0.0179664\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0081361\tvalid_1's binary_logloss: 0.0237993\n",
      "Early stopping, best iteration is:\n",
      "[1204]\ttraining's binary_logloss: 0.00758061\tvalid_1's binary_logloss: 0.0235787\n",
      "total_logloss : 0.02626 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79304944936b4b71aa72dd0be561421e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------  done model pred  ---------------\n",
      "[0.0378 0.0353 0.0247 0.0313 0.0306]\n",
      "total_gal_logloss: 0.031957967311322784\n",
      "[0.1203 0.3141 0.1176 0.1969 0.0183 0.1027 0.0124 0.2884 0.0263]\n",
      "total_ex_gal_logloss: 0.13298510203787375\n",
      "CPU times: user 1h 25min 30s, sys: 19min 24s, total: 1h 44min 54s\n",
      "Wall time: 28min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 予測\n",
    "print('---------------  start gal_model pred  ---------------')\n",
    "importances_gal,oof_gal_total,preds_gal,logloss_gal = galaxy_model(galaxy='gal',pred=True,layout=False,seed_list=[1])\n",
    "\n",
    "print('---------------  start ex_gal_model pred  ---------------')\n",
    "importances_ex_gal,oof_ex_gal_total,preds_ex_gal,logloss_ex_gal = galaxy_model(galaxy='ex_gal',pred=True,layout=False,seed_list=[1])\n",
    "\n",
    "print('---------------  done model pred  ---------------')\n",
    "print(np.round(logloss_gal, decimals=4))\n",
    "print('total_gal_logloss:',np.array(logloss_gal).mean())\n",
    "print(np.round(logloss_ex_gal, decimals=4))\n",
    "print('total_ex_gal_logloss:',np.array(logloss_ex_gal).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2325, 5)\n",
      "(5523, 9)\n",
      "(390510, 5)\n",
      "(3102380, 9)\n"
     ]
    }
   ],
   "source": [
    "# check shape\n",
    "print(oof_gal_total.shape)\n",
    "print(oof_ex_gal_total.shape)\n",
    "print(preds_gal.shape)\n",
    "print(preds_ex_gal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_gal_total['prob_sum'] = oof_gal_total.iloc[:,1:].sum(axis=1)\n",
    "oof_gal_total['prob_med'] = oof_gal_total.iloc[:,1:].median(axis=1)\n",
    "oof_ex_gal_total['prob_sum'] = oof_ex_gal_total.iloc[:,1:].sum(axis=1)\n",
    "oof_ex_gal_total['prob_med'] = oof_ex_gal_total.iloc[:,1:].median(axis=1)\n",
    "\n",
    "preds_gal['prob_sum'] = preds_gal.iloc[:,1:].sum(axis=1)\n",
    "preds_gal['prob_med'] = preds_gal.iloc[:,1:].median(axis=1)\n",
    "preds_ex_gal['prob_sum'] = preds_ex_gal.iloc[:,1:].sum(axis=1)\n",
    "preds_ex_gal['prob_med'] = preds_ex_gal.iloc[:,1:].median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importance_ex_gal,oof_ex_gal_total,preds_ex_gal,auc_class_exgal = galaxy_model(galaxy='ex_gal',pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ex_gal_id = train_ex_gal_id.reset_index()\n",
    "train_gal_id = train_gal_id.reset_index()\n",
    "test_ex_gal_id = test_ex_gal_id.reset_index()\n",
    "test_gal_id = test_gal_id.reset_index()\n",
    "del train_ex_gal_id['index'],train_gal_id['index'],test_ex_gal_id['index'],test_gal_id['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_gal = pd.merge(train_gal_id,oof_gal_total,left_index=True,right_index=True,how='left')\n",
    "preds_gal = pd.merge(test_gal_id,preds_gal,left_index=True,right_index=True,how='left')\n",
    "oof_ex_gal = pd.merge(train_ex_gal_id,oof_ex_gal_total,left_index=True,right_index=True,how='left')\n",
    "preds_ex_gal = pd.merge(test_ex_gal_id,preds_ex_gal,left_index=True,right_index=True,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_result = oof_gal.append(oof_ex_gal,sort=True).fillna(0)\n",
    "preds_result = preds_gal.append(preds_ex_gal,sort=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3492890, 17)\n",
      "(7848, 17)\n"
     ]
    }
   ],
   "source": [
    "print(preds_result.shape)\n",
    "print(oof_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>prob_med</th>\n",
       "      <th>prob_sum</th>\n",
       "      <th>target_15</th>\n",
       "      <th>target_16</th>\n",
       "      <th>target_42</th>\n",
       "      <th>target_52</th>\n",
       "      <th>target_53</th>\n",
       "      <th>target_6</th>\n",
       "      <th>target_62</th>\n",
       "      <th>target_64</th>\n",
       "      <th>target_65</th>\n",
       "      <th>target_67</th>\n",
       "      <th>target_88</th>\n",
       "      <th>target_90</th>\n",
       "      <th>target_92</th>\n",
       "      <th>target_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>168</td>\n",
       "      <td>0.004919</td>\n",
       "      <td>1.004749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1063</td>\n",
       "      <td>0.025563</td>\n",
       "      <td>1.011062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025563</td>\n",
       "      <td>0.006437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.982864</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2270</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.998139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.004003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_id  prob_med  prob_sum  target_15  target_16  target_42  target_52  \\\n",
       "0        168  0.004919  1.004749        0.0   0.998177        0.0        0.0   \n",
       "1       1063  0.025563  1.011062        0.0   0.000449        0.0        0.0   \n",
       "2       2270  0.001267  0.998139        0.0   0.000955        0.0        0.0   \n",
       "\n",
       "   target_53  target_6  target_62  target_64  target_65  target_67  target_88  \\\n",
       "0   0.000801  0.000310        0.0        0.0   0.004919        0.0        0.0   \n",
       "1   0.025563  0.006437        0.0        0.0   0.002186        0.0        0.0   \n",
       "2   0.001128  0.004003        0.0        0.0   0.994789        0.0        0.0   \n",
       "\n",
       "   target_90  target_92  target_95  \n",
       "0        0.0   0.000853        0.0  \n",
       "1        0.0   0.982864        0.0  \n",
       "2        0.0   0.001267        0.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_result.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_result.to_pickle('../input/oof_result_20181217_v2.pickle')\n",
    "preds_result.to_pickle('../input/preds_result_20181217_v2.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
